{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ee540ed-31b0-4481-bf05-34c2ff034518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52d41c76-1881-4835-b08b-ab416cbd0a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#import opencv as cv2\n",
    "import os\n",
    "#from PIL import Image\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "# Load the DeepLabV3 model pre-trained on the COCO dataset\n",
    "model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append((filename, img))\n",
    "    return images\n",
    "\n",
    "def segment_humans(image):\n",
    "    h, w, _ = image.shape\n",
    "    input_image = cv2.resize(image, (224, 224))\n",
    "    input_image = tf.keras.applications.resnet50.preprocess_input(input_image)\n",
    "    input_image = np.expand_dims(input_image, axis=0)\n",
    "\n",
    "    # Get the segmentation mask\n",
    "    preds = model.predict(input_image)\n",
    "    preds = np.argmax(preds.squeeze(), axis=-1)\n",
    "\n",
    "    # Resize the mask to the original image size\n",
    "    preds = cv2.resize(preds, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Create a binary mask where the human is located\n",
    "    mask = preds == 1  # Class ID 15 corresponds to humans in COCO dataset\n",
    "\n",
    "    return mask\n",
    "\n",
    "def save_human_cutouts(images, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for filename, image in images:\n",
    "        mask = segment_humans(image)\n",
    "        cv2.imshow(\"Image\", mask.astype(np.uint8))\n",
    "        cv2.waitKey()\n",
    "        cv2.destroyAllWindows()\n",
    "        human_cutout = cv2.bitwise_and(image, image, mask=mask.astype(np.uint8))\n",
    "\n",
    "        # Save the cutout\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, human_cutout)\n",
    "\n",
    "input_folder = 'INPUT FOLDER'\n",
    "output_folder = input_folder +'\\out'\n",
    "\n",
    "images = load_images_from_folder(input_folder)\n",
    "save_human_cutouts(images, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89d31408-d83f-4c78-a64c-9608986fab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "# Load the DeepLabV3 model\n",
    "MODEL_NAME = 'deeplabv3_mnv2_pascal_train_aug'\n",
    "_DOWNLOAD_URL_PREFIX = \"http://download.tensorflow.org/models/\"\n",
    "_MODEL_URLS = {\n",
    "    'deeplabv3_mnv2_pascal_train_aug': 'deeplabv3_mnv2_pascal_train_aug_2018_01_29.tar.gz',\n",
    "}\n",
    "_TARBALL_NAME = 'deeplab_model.tar.gz'\n",
    "\n",
    "model_dir = tf.keras.utils.get_file(\n",
    "    fname=_TARBALL_NAME,\n",
    "    origin=_DOWNLOAD_URL_PREFIX + _MODEL_URLS[MODEL_NAME],\n",
    "    untar=True)\n",
    "\n",
    "model_path = os.path.join(model_dir, \"frozen_inference_graph.pb\")\n",
    "\n",
    "def load_model(model_path):\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        graph_def = tf.compat.v1.GraphDef()\n",
    "        with tf.io.gfile.GFile(model_path, \"rb\") as f:\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            tf.import_graph_def(graph_def, name=\"\")\n",
    "    return graph\n",
    "\n",
    "def segment_humans(image, graph):\n",
    "    input_size = 513\n",
    "    width, height = image.shape[1], image.shape[0]\n",
    "    resized_image = cv2.resize(image, (input_size, input_size))\n",
    "    resized_image = np.asarray(resized_image, dtype=np.uint8)\n",
    "\n",
    "    with tf.compat.v1.Session(graph=graph) as sess:\n",
    "        input_tensor = graph.get_tensor_by_name('ImageTensor:0')\n",
    "        output_tensor = graph.get_tensor_by_name('SemanticPredictions:0')\n",
    "        predictions = sess.run(output_tensor, feed_dict={input_tensor: [resized_image]})\n",
    "        predictions = predictions[0]\n",
    "\n",
    "    mask = cv2.resize(predictions.astype(np.uint8), (width, height), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # Create binary mask for the human class\n",
    "    human_mask = (mask == 15).astype(np.uint8)\n",
    "    return human_mask\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append((filename, img))\n",
    "    return images\n",
    "\n",
    "def save_human_cutouts(images, output_folder, graph):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for filename, image in images:\n",
    "        mask = segment_humans(image, graph)\n",
    "        alpha_channel = mask * 255\n",
    "\n",
    "        # Create a 4-channel image with transparency\n",
    "        b, g, r = cv2.split(image)\n",
    "        rgba = [b, g, r, alpha_channel]\n",
    "        human_cutout = cv2.merge(rgba)\n",
    "\n",
    "        # Save the cutout as a PNG with transparency\n",
    "        output_path = os.path.join(output_folder, os.path.splitext(filename)[0] + '.png')\n",
    "        cv2.imwrite(output_path, human_cutout)\n",
    "        \n",
    "input_folder = 'INPUT FOLDER'\n",
    "output_folder =  input_folder +'\\out'\n",
    "\n",
    "graph = load_model(model_path)\n",
    "images = load_images_from_folder(input_folder)\n",
    "save_human_cutouts(images, output_folder, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca542fa4-20ab-4b61-917a-d4e700f9ed14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
